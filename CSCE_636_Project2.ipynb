{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YunDudali/YunDudali-TAMU_CSCE636_Project_2-/blob/main/CSCE_636_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TAMU - CSCE636 Project_2**"
      ],
      "metadata": {
        "id": "xfKdsvWnawAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Requirement : **\n",
        "\n",
        "This project is on machine translation for two \"artificial\" languages: an \"Input Language\" and an \"Output Language\". We want to build a model to translate the texts in the \"Input Language\" to texts in the \"Output Language\". For example, a text in the \"Input Language\" can be \"a g b f a f a e a k a j c f b f c d a k a k c e b g a h a k b d b f b f b d c d \" , and its translation to the \"Output Language\" is \"b f c f b f c d a j e f g c e b g a k i j b d b f a k l m b f b d a h ed ee ef a k k eg a k h eh a e ei c d a f ej ek a g d el\".\n",
        "\n",
        "As a training dataset, a list of 5,000 texts in the Input Language are here, and the corresponding list of 5,000 texts in the Output Language are here.  They are two lists of strings in Python.)\n",
        "\n",
        "Your task is to design and train a good model, which can take texts in the \"Input language\" as its input, translate them to the corresponding texts in the \"Output Language\" and output them. \n",
        "\n"
      ],
      "metadata": {
        "id": "AR1DN5Tva_E5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Projetct Details Code: **"
      ],
      "metadata": {
        "id": "7Yg8473rdtIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This Block is for Testing, Please change the file path for training set,  testing set and the model** \\\\\n",
        "\n",
        "I use three independent \"Transformer\" models is to emulating the concept of Random Forest to get the majority vote for each output token during the translation process. In this case, the translation can be more accurate and stable.\n",
        "\n",
        "The translation process might cost some time."
      ],
      "metadata": {
        "id": "-M_RUKFOmzjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load Model here\n",
        "model = keras.models.load_model(\"/content/drive/MyDrive/courses/Deep Learning CSCE 636/Proj2/yundu.keras\")\n",
        "# Please change the training input and training output file path for the TextVectorization purpose\n",
        "training_source_path = '/content/drive/MyDrive/courses/Deep Learning CSCE 636/Proj2/DS_5_train_input'\n",
        "training_target_path = '/content/drive/MyDrive/courses/Deep Learning CSCE 636/Proj2/DS_5_train_output'\n",
        "# Please change the testing input and testing output file path for the the prediction\n",
        "testing_source_path = '/content/drive/MyDrive/courses/Deep Learning CSCE 636/Proj2/DS_5_train_input'\n",
        "testing_target_path = '/content/drive/MyDrive/courses/Deep Learning CSCE 636/Proj2/DS_5_train_output'\n",
        "\n",
        "##-----Testing Codes start here---\n",
        "training_source = pickle.load(open(training_source_path, 'rb'))\n",
        "training_target = pickle.load(open(training_target_path, 'rb'))\n",
        "for i in range(len(training_target)):\n",
        "    training_target[i] = \"[start] \" + training_target[i] + \" [end]\"\n",
        "source_vectorization = layers.TextVectorization(max_tokens=20000, output_mode='int', output_sequence_length=256)\n",
        "target_vectorization = layers.TextVectorization(max_tokens=20000, output_mode='int', output_sequence_length=256 + 1)\n",
        "source_vectorization.adapt(training_source)\n",
        "target_vectorization.adapt(training_target)\n",
        "\n",
        "testing_source = pickle.load(open(testing_source_path, 'rb'))\n",
        "testing_target = pickle.load(open(testing_target_path, 'rb'))\n",
        "for i in range(len(testing_target)):\n",
        "    testing_target[i] = \"[start] \" + testing_target[i] + \" [end]\"\n",
        "\n",
        "##-----vectorization---------------\n",
        "target_vocab = target_vectorization.get_vocabulary()\n",
        "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
        "\n",
        "\n",
        "##-----Translate----------------\n",
        "def decoded_seq(input_sentence_):\n",
        "    tokenized_input = source_vectorization([input_sentence_])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(256):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        [prediction1, prediction2, prediction3] = model([tokenized_input, tokenized_target_sentence])\n",
        "        index_1 = np.argmax(prediction1[0, i, :])\n",
        "        index_2 = np.argmax(prediction2[0, i, :])\n",
        "        index_3 = np.argmax(prediction3[0, i, :])\n",
        "\n",
        "        index_a = Counter([index_1, index_2, index_3]).most_common()[0][0]\n",
        "        sampled_token = target_index_lookup[index_a]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"end\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "pre = []  # This is the translated sentences\n",
        "num_words = 0\n",
        "accu = 0\n",
        "num_sentence = 10   # len(testing_source)\n",
        "for idx in range(num_sentence):\n",
        "    input_sentence = testing_source[idx]\n",
        "    output_sentence = testing_target[idx]\n",
        "    decoder_out = decoded_seq(input_sentence)\n",
        "\n",
        "    output_sentence_ = output_sentence.replace(\"[start]\", \"\").replace(\"[end]\", \"\").split()\n",
        "    decoder_out_ = decoder_out.replace(\"[start]\", \"\").replace(\"end\", \"\").split()\n",
        "    pre.append(decoder_out.replace(\"[start]\", \"\").replace(\"end\", \"\"))\n",
        "\n",
        "    length = min(len(output_sentence_), len(decoder_out_))\n",
        "    accu += np.sum(np.array(output_sentence_[:length]) == np.array(decoder_out_[:length]))\n",
        "    num_words += len(output_sentence_)\n",
        "\n",
        "print(\"Translation Accuracy:\")\n",
        "print(accu / num_words)"
      ],
      "metadata": {
        "id": "ZvNRZulymw9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d799d45f-61a3-4274-ccdc-cabd75e35e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Translation Accuracy:\n",
            "0.7985480943738656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA3vp2IiEpAq",
        "outputId": "146bcade-9dbf-4033-e808-4064fd0bf6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' b f c f b f c d a j e f g c e b g a k i j b d b f a k l m b f b d a h ed ee ef a k k eg a k h eh a e ei c d a f ej ek a g d el ',\n",
              " ' b f b e c d b g c g a i f g h a f e i c e a i d j k a e l a e m c f c d a e ef c d a i ee eg eh a e ei a k ed ej ',\n",
              " ' c f b e c d b f b e a k g h b e a k i j b d c d a h k l m c d a e ee a h f ed ef a g e eg b f a d eh ei a k d ej ',\n",
              " ' b g b e c g a g e f c g a j d g h b g b f a g j k b f a k l m b e a k ed ee c e a j i ef eg c e b g a h eh ei ej ',\n",
              " ' b d c f c e a f e f c d a d g h c f c f a j i j k a e l c f a k m ed c d c d a f ef eg b g c g a g ei ej a h ee eh ek b d c e a h el em fd c e a g fe ff a k d fg ',\n",
              " ' c g b g b d c f c g a e h a f g i a d f j c e a f k l c d c e a e ee a g ed ef a d m eg b d a j e eh ei a k d ej ',\n",
              " ' c e c f b e a d e f c d c g b e c f c d a k k l a h i j m a h g h ed a e ee a g d ef c d b g a h eg eh ei ',\n",
              " ' c e c g b e a e f a e g a d e h c e a d i j a d d k a e l c f a d m ed b f c d c f a k eg eh b f a i ef ei ej ',\n",
              " ' b g a e d b d b f c f a h f g h a e i a e j b f b f a k l m a d k ed a d e ee c g a e eg a k ef eh ',\n",
              " ' b e a e d b e a g e f b g b f a d h i c f b g a k k l c e a i j m ed b g a e ef b d a h ee eg eh b e c e a d ej ek a d ei el a d g em ']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This Block is the Transformer Model**"
      ],
      "metadata": {
        "id": "Bzu0s49En0Lq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEtcwU0EP9HD"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pickle\n",
        "\n",
        "##-----import data-----------------\n",
        "source_path = './DS_5_train_input'\n",
        "target_path = './DS_5_train_output'\n",
        "source = pickle.load(open(source_path, 'rb'))\n",
        "target = pickle.load(open(target_path, 'rb'))\n",
        "\n",
        "temp = list(zip(source, target))\n",
        "random.shuffle(temp)\n",
        "source, target = zip(*temp)\n",
        "source, target = list(source), list(target)\n",
        "\n",
        "##-----Pre-process-----------------\n",
        "# Add \"start\" and \"end\" tokens to every output sentence\n",
        "for i in range(len(target)):\n",
        "    target[i] = \"[start] \" + target[i] + \" [end]\"\n",
        "# Saperate the data set into training and validation set\n",
        "val_source = source[:1000]\n",
        "val_target = target[:1000]\n",
        "train_source = source[1000:]\n",
        "train_target = target[1000:]\n",
        "\n",
        "##-----Global Variables------------\n",
        "max_tokens = 20000\n",
        "max_sequence_length = 256\n",
        "\n",
        "embed_dim = 256\n",
        "num_heads = 8\n",
        "dense_dim = 1024\n",
        "\n",
        "num_encoder_block = 1\n",
        "num_decoder_block = 1\n",
        "\n",
        "##-----vectorization---------------\n",
        "source_vectorization = layers.TextVectorization(max_tokens=max_tokens, output_mode='int', output_sequence_length=max_sequence_length)\n",
        "target_vectorization = layers.TextVectorization(max_tokens=max_tokens, output_mode='int', output_sequence_length=max_sequence_length + 1)\n",
        "source_vectorization.adapt(source)\n",
        "target_vectorization.adapt(target)\n",
        "\n",
        "##-----Data Set Creation---------\n",
        "def format_dataset(src, tgt):\n",
        "    src = source_vectorization(src)\n",
        "    tgt = target_vectorization(tgt)\n",
        "    return {\"source\": src, \"target\": tgt[:, :-1], }, tgt[:, 1:]\n",
        "\n",
        "\n",
        "def make_dataset(src, tgt):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((src, tgt))\n",
        "    dataset = dataset.batch(32)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(32).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_source, train_target)\n",
        "val_ds = make_dataset(val_source, val_target)\n",
        "\n",
        "\n",
        "##-----Transformer model-----------\n",
        "# Transformer Block\n",
        "def Transformer_Encoder_Block(inputs, mask_, embed_dim_, num_heads_, dense_dim_):\n",
        "    x = layers.MultiHeadAttention(num_heads=num_heads_, key_dim=embed_dim, dropout=0.2)(inputs, inputs, attention_mask=mask_[:, tf.newaxis, :])\n",
        "    res = layers.LayerNormalization()(x + inputs)\n",
        "    res = layers.Dropout(0.2)(res)\n",
        "    x = layers.Dense(dense_dim_, activation=\"relu\")(res)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(embed_dim_)(x)\n",
        "    out = layers.LayerNormalization()(x + res)\n",
        "    return out\n",
        "\n",
        "\n",
        "# Positional Embedding\n",
        "def Positional_Embedding(inputs):\n",
        "    length = tf.shape(inputs)[-1]\n",
        "    positions = tf.range(start=0, limit=length, delta=1)\n",
        "    embedded_tokens = layers.Embedding(input_dim=max_tokens, output_dim=embed_dim)(inputs)\n",
        "    embedded_positions = layers.Embedding(input_dim=max_sequence_length, output_dim=embed_dim)(positions)\n",
        "    embedded_out = embedded_positions + embedded_tokens\n",
        "    return embedded_out, tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "# Decoder Mask\n",
        "def Decoder_Attention_Mask(inputs):\n",
        "    input_shape = tf.shape(inputs)\n",
        "    batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "    i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "    j = tf.range(sequence_length)\n",
        "    mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "    mask = tf.reshape(mask, (1, sequence_length, sequence_length))\n",
        "    mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "\n",
        "# Transformer Decoder Block\n",
        "def Transformer_Decoder_Block(inputs, encoder_outputs, mask_, embed_dim_, num_heads_, dense_dim_):\n",
        "    causal_mask = Decoder_Attention_Mask(inputs)\n",
        "    padding_mask = tf.cast(mask_[:, tf.newaxis, :], dtype=\"int32\")\n",
        "    padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "    attention_output1 = layers.MultiHeadAttention(num_heads=num_heads_, key_dim=embed_dim_, dropout=0.2)(query=inputs, value=inputs, key=inputs, attention_mask=causal_mask)\n",
        "    attention_output1 = layers.LayerNormalization()(attention_output1 + inputs)\n",
        "\n",
        "    attention_output2 = layers.MultiHeadAttention(num_heads=num_heads_, key_dim=embed_dim_, dropout=0.2)(query=attention_output1,\n",
        "                                                         value=encoder_outputs,\n",
        "                                                         key=encoder_outputs,\n",
        "                                                         attention_mask=padding_mask)\n",
        "    attention_output2 = layers.LayerNormalization()(attention_output1 + attention_output2)\n",
        "    attention_output2 = layers.Dropout(0.2)(attention_output2)\n",
        "    x = layers.Dense(dense_dim_, activation=\"relu\")(attention_output2)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(embed_dim_)(x)\n",
        "    out = layers.LayerNormalization()(x + attention_output2)\n",
        "    return out\n",
        "\n",
        "\n",
        "# Build the whole Transformer Model\n",
        "input_source = keras.Input(shape=(max_sequence_length,), dtype=\"int64\", name=\"source\")\n",
        "input_target = keras.Input(shape=(max_sequence_length,), dtype=\"int64\", name=\"target\")\n",
        "\n",
        "embedded_source, source_mask = Positional_Embedding(input_source)\n",
        "embedded_target, target_mask = Positional_Embedding(input_target)\n",
        "\n",
        "encoder_out = embedded_source\n",
        "for i in range(num_encoder_block):\n",
        "    encoder_out = Transformer_Encoder_Block(inputs=encoder_out, mask_=source_mask, embed_dim_=embed_dim, num_heads_=num_heads, dense_dim_=dense_dim)\n",
        "decoder_out = embedded_target\n",
        "for i in range(num_decoder_block):\n",
        "    decoder_out = Transformer_Decoder_Block(inputs=decoder_out, encoder_outputs=encoder_out, mask_=target_mask, embed_dim_=embed_dim, num_heads_=num_heads, dense_dim_=dense_dim)\n",
        "decoder_out = layers.Dense(max_tokens, activation=\"softmax\")(decoder_out)\n",
        "\n",
        "\n",
        "transformer = keras.Model([input_source, input_target], decoder_out)\n",
        "transformer.summary()\n",
        "\n",
        "transformer.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"./project2_v2.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "train_source, train_target = np.asarray(train_source), np.asarray(train_target)\n",
        "val_source, val_target = np.asarray(val_source), np.asarray(val_target)\n",
        "transformer.fit(train_ds, epochs=500,\n",
        "                callbacks=callbacks,\n",
        "                validation_data=val_ds, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This Block is compiling three different Transformer Models using previous block**\n",
        "\n",
        "The purpose of using three Transformer models is to emulating the concept of Random Forest to get the majority vote for each output token. In this case, the translation can be more accurate and stable."
      ],
      "metadata": {
        "id": "tS1R5t0CoxfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "transformer1 = keras.models.load_model(\"./project2_v1.keras\", compile=False)\n",
        "transformer2 = keras.models.load_model(\"./project2_v2.keras\", compile=False)\n",
        "transformer3 = keras.models.load_model(\"./project2_v3.keras\", compile=False)\n",
        "\n",
        "transformer1._name = \"trans_1\"\n",
        "transformer2._name = \"trans_2\"\n",
        "transformer3._name = \"trans_3\"\n",
        "\n",
        "max_sequence_length = 256\n",
        "\n",
        "input_source = keras.Input(shape=(max_sequence_length,), dtype=\"int64\", name=\"source\")\n",
        "input_target = keras.Input(shape=(max_sequence_length,), dtype=\"int64\", name=\"target\")\n",
        "\n",
        "# transformer1.get_layer(index=0) = input_target\n",
        "\n",
        "output1 = transformer1([input_source, input_target])\n",
        "output2 = transformer2([input_source, input_target])\n",
        "output3 = transformer3([input_source, input_target])\n",
        "\n",
        "transformer = keras.Model([input_source, input_target], [output1, output2, output3])\n",
        "transformer.summary()\n",
        "transformer.save(\"./transformer_compile2.keras\")\n"
      ],
      "metadata": {
        "id": "NdJGW8c3Wzf6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}